{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, random_feature=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_feature = random_feature\n",
    "        self.tree = None\n",
    "        self.feature_importances = None  # Optional\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_importances = np.zeros(X.shape[1])\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_targets = np.unique(y)\n",
    "\n",
    "        if len(unique_targets) == 1:\n",
    "            return unique_targets[0]\n",
    "        if num_samples < self.min_samples_split:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "\n",
    "        # Ensure that random_feature is within bounds\n",
    "        num_random_features = min(self.random_feature, num_features)\n",
    "\n",
    "        # Randomly select `num_random_features` features\n",
    "        feature_indices = np.random.choice(num_features, num_random_features, replace=False)\n",
    "\n",
    "        best_split = self._best_split(X, y, feature_indices)\n",
    "        if best_split is None:\n",
    "            return np.mean(y) if len(y) > 0 else 0\n",
    "\n",
    "        left_mask, right_mask = self._split_data(X[:, best_split['feature']], best_split['value'])\n",
    "\n",
    "        left_target, right_target = y[left_mask], y[right_mask]\n",
    "        mse_before = self._calculate_mse(y, y)\n",
    "        mse_after = self._calculate_mse(left_target, right_target)\n",
    "        reduction_in_mse = mse_before - mse_after\n",
    "\n",
    "        self.feature_importances[best_split['feature']] += reduction_in_mse\n",
    "\n",
    "        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'value': best_split['value'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _best_split(self, X, y, feature_indices):\n",
    "        best_mse = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature in feature_indices:\n",
    "            values = np.unique(X[:, feature])\n",
    "            for value in values:\n",
    "                left_mask, right_mask = self._split_data(X[:, feature], value)\n",
    "\n",
    "                if len(left_mask) == 0 or len(right_mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                mse = self._calculate_mse(y[left_mask], y[right_mask])\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _split_data(self, feature_column, value):\n",
    "        left_mask = feature_column <= value\n",
    "        right_mask = ~left_mask\n",
    "        return left_mask, right_mask\n",
    "\n",
    "    def _calculate_mse(self, left_target, right_target):\n",
    "        if len(left_target) == 0 or len(right_target) == 0:\n",
    "            return float('inf')\n",
    "        left_mse = np.mean((left_target - np.mean(left_target)) ** 2) if len(left_target) > 0 else 0\n",
    "        right_mse = np.mean((right_target - np.mean(right_target)) ** 2) if len(right_target) > 0 else 0\n",
    "        return (len(left_target) * left_mse + len(right_target) * right_mse) / (len(left_target) + len(right_target))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            if x[tree['feature']] <= tree['value']:\n",
    "                return self._predict_single(x, tree['left'])\n",
    "            else:\n",
    "                return self._predict_single(x, tree['right'])\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, random_feature=5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.random_feature = random_feature\n",
    "        self.trees = []\n",
    "        self.feature_importances_ = None  # Optional\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        feature_importances = np.zeros(X.shape[1])\n",
    "        for _ in range(self.n_estimators):\n",
    "\n",
    "            bootstrap_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_feature=self.random_feature\n",
    "            )\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            feature_importances += tree.feature_importances\n",
    "        self.feature_importances_ = feature_importances / self.n_estimators\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)\n",
    "    \n",
    "def TrainTest_Split(X, y, test_size=0.4, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    indices = np.random.permutation(len(X))\n",
    "    X_shuffled = X[indices]\n",
    "    y_shuffled = y[indices]\n",
    "\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X_shuffled[:split_idx], X_shuffled[split_idx:]\n",
    "    y_train, y_test = y_shuffled[:split_idx], y_shuffled[split_idx:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "   brokered_by    status      price  bed  bath  acre_lot     street  \\\n",
      "0      92147.0  for_sale   110000.0  7.0   3.0      0.09  1842706.0   \n",
      "1      94933.0  for_sale   950000.0  5.0   4.0      0.99  1260473.0   \n",
      "2     103341.0  for_sale  6899000.0  4.0   6.0      0.83    17467.0   \n",
      "3      21163.0  for_sale   525000.0  3.0   3.0      0.45  1813270.0   \n",
      "4      67455.0  for_sale   289900.0  3.0   2.0      0.36  1698080.0   \n",
      "\n",
      "           city           state  zip_code  house_size prev_sold_date  \\\n",
      "0        Dorado     Puerto Rico     949.0      1192.0     2019-06-28   \n",
      "1  Saint Thomas  Virgin Islands     802.0      5000.0     2013-10-11   \n",
      "2  Saint Thomas  Virgin Islands     802.0      4600.0     2018-04-05   \n",
      "3        Agawam   Massachusetts    1001.0      2314.0     2014-06-25   \n",
      "4        Agawam   Massachusetts    1001.0      1276.0     2012-10-12   \n",
      "\n",
      "   city_encoded  state_encoded  \n",
      "0             0              0  \n",
      "1             1              1  \n",
      "2             1              1  \n",
      "3             2              2  \n",
      "4             2              2  \n",
      "\n",
      "Training set size: 40000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "data = pd.read_csv(\"Realtor50K.csv\")\n",
    "\n",
    "print(\"Data sample:\")\n",
    "print(data.head())\n",
    "\n",
    "X = data[['brokered_by', 'bed', 'bath', 'acre_lot', 'street', 'zip_code', 'house_size', 'city_encoded', 'state_encoded']].values\n",
    "y = data['price'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=10, random_feature=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_pred_rounded = np.round(y_test_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample comparison (True vs Predicted on Test Set):\n",
      "   True Price  Predicted Price\n",
      "0    889000.0        802107.03\n",
      "1    363000.0        353569.85\n",
      "2    629900.0        714790.59\n",
      "3   1325000.0       1590487.44\n",
      "4    299000.0        290850.18\n",
      "5    139999.0        276144.21\n",
      "6    349900.0        606312.51\n",
      "7    679900.0        454093.95\n",
      "8    599000.0        462517.74\n",
      "9    164900.0        183858.62\n",
      "\n",
      "Model Evaluation Metrics on Test Set:\n",
      "R² Score: 0.5659\n",
      "Mean Squared Error (MSE): 694077106458.5076\n",
      "Mean Absolute Error (MAE): 258081.5723\n",
      "\n",
      "Feature Importances: [2.13378555e+14 1.09593331e+14 1.11061593e+14 2.53378438e+14\n",
      " 2.14692850e+14 2.41202550e+14 3.50684328e+14 2.14162447e+14\n",
      " 5.47714302e+13]\n"
     ]
    }
   ],
   "source": [
    "comparison_test = pd.DataFrame({\n",
    "    'True Price': y_test,\n",
    "    'Predicted Price': y_test_pred_rounded\n",
    "})\n",
    "\n",
    "print(\"\\nSample comparison (True vs Predicted on Test Set):\")\n",
    "print(comparison_test.head(10))\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics on Test Set:\")\n",
    "print(f\"R² Score: {r2_test:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_test:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n",
    "\n",
    "print(\"\\nFeature Importances:\", rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf, 'RandomForest_Model.joblib')\n",
    "\n",
    "print(\"Model saved!\")\n",
    "\n",
    "loaded_rf = joblib.load('RandomForest_Model.joblib')\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Function\n",
    "\n",
    "# Library scikit-learn: Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Library numpy: Calculation of r2 score, MSE, MAE\n",
    "import numpy as np\n",
    "def r2_score_manual(true_values, predicted_values):\n",
    "    true_values = np.array(true_values)\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    \n",
    "    true_mean = np.mean(true_values)\n",
    "    ss_total = np.sum((true_values - true_mean) ** 2)\n",
    "    ss_residual = np.sum((true_values - predicted_values) ** 2)\n",
    "    \n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "def mse_manual(true_values, predicted_values):\n",
    "    true_values = np.array(true_values)\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    return np.mean((true_values - predicted_values) ** 2)\n",
    "\n",
    "def mae_manual(true_values, predicted_values):\n",
    "    true_values = np.array(true_values)\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    return np.mean(np.abs(true_values - predicted_values))\n",
    "\n",
    "# Library scikit-learn: Categorical Encoding & Machine Learning Algorithm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_csv(\"Realtor50K.csv\")\n",
    "label_encoders = {}\n",
    "for column in ['state', 'city']:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X = df.drop(columns=['price', 'status', 'prev_sold_date'])\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
